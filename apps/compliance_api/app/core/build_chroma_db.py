# build_chroma_db.py
import os
import shutil
from dotenv import load_dotenv  # ì¶”ê°€: .env íŒŒì¼ ë¡œë“œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma

# --- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ì— ìˆëŠ” .env íŒŒì¼ì„ ì°¾ì•„ ì½ì–´ì˜µë‹ˆë‹¤.
load_dotenv() 

# --- ê²½ë¡œ ì„¤ì • ---
# í˜„ì¬ í„°ë¯¸ë„ ì‹¤í–‰ ìœ„ì¹˜ê°€ compliance_api í´ë”ì´ë¯€ë¡œ ìƒëŒ€ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
BASE_KNOWLEDGE_PATH = "resources/knowledge_base/"
VECTOR_DB_PATH = "vector_db/"

def build_vector_store():
    # 1. API í‚¤ í™•ì¸ (ë””ë²„ê¹…ìš©)
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ ì—ëŸ¬: OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ íŒ: í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ì— .env íŒŒì¼ì´ ìˆëŠ”ì§€, ë‚´ë¶€ì— OPENAI_API_KEY=sk-... ê°€ ì •í™•íˆ ì‘ì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return

    print(f"ğŸ”‘ API í‚¤ í™•ì¸ ì™„ë£Œ: {api_key[:10]}...") # ë³´ì•ˆì„ ìœ„í•´ ì•ë¶€ë¶„ë§Œ ì¶œë ¥

    # 2. ê¸°ì¡´ DB ì´ˆê¸°í™”
    if os.path.exists(VECTOR_DB_PATH):
        print(f"â™»ï¸ ê¸°ì¡´ Vector DB({VECTOR_DB_PATH})ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤...")
        shutil.rmtree(VECTOR_DB_PATH)

    # 3. ëª¨ë“  í•˜ìœ„ í´ë”ì—ì„œ PDF ë¡œë“œ
    print(f"ğŸ“‚ '{BASE_KNOWLEDGE_PATH}'ì—ì„œ ë°ì´í„°ë¥¼ ì½ì–´ì˜¤ëŠ” ì¤‘...")
    loader = DirectoryLoader(
        BASE_KNOWLEDGE_PATH, 
        glob="**/*.pdf", 
        loader_cls=PyPDFLoader,
        recursive=True
    )
    documents = loader.load()
    
    if not documents:
        print(f"âš ï¸ ê²½ê³ : '{BASE_KNOWLEDGE_PATH}' ê²½ë¡œì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"âœ… ì´ {len(documents)} í˜ì´ì§€ì˜ ë¬¸ì„œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")

    # 4. í…ìŠ¤íŠ¸ ë¶„í•  (Chunking)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=120, separators=["\n\n", "\n", " ", ""])
    chunks = text_splitter.split_documents(documents)
    print(f"âœ‚ï¸ ë¬¸ì„œë¥¼ {len(chunks)}ê°œì˜ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ì—ˆìŠµë‹ˆë‹¤.")

    # 5. VectorDB ìƒì„± ë° ì˜êµ¬ ì €ì¥
    print("ğŸ§  ì„ë² ë”© ìƒì„± ì¤‘... (ë°ì´í„° ì–‘ì— ë”°ë¼ ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    
    vectorstore = Chroma.from_documents(
        documents=chunks,
        embedding=embeddings,
        persist_directory=VECTOR_DB_PATH
    )
    
    print(f"ğŸš€ Vector DB êµ¬ì¶• ì™„ë£Œ! ì €ì¥ ìœ„ì¹˜: {VECTOR_DB_PATH}")

if __name__ == "__main__":
    build_vector_store()