{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dae4e1d5",
   "metadata": {},
   "source": [
    "### Cell 1 (Imports): \n",
    "프로젝트 전역에서 사용하는 라이브러리를 단 한 번만 정의하여 의존성 충돌을 방지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5445b74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install \"openai>=1.40.0\" python-dotenv pandas openpyxl numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "098249a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 1: Imports (ONLY HERE) =====\n",
    "import os, re, json\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16105ac0",
   "metadata": {},
   "source": [
    "### Cell 2 (Constants): \n",
    "시스템의 '뇌' 역할을 하는 정책들입니다. UNIT_TOKENS(단위 사전)와 PATTERNS_BY_SLOT(컬럼명 패턴)을 이곳에서 관리하여,<br>\n",
    "비즈니스 로직 수정 없이 상수 값 변경만으로 시스템 운영이 가능하게 설계되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66af07a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT] .env loaded\n",
      "  - OPENAI_API_KEY: SET\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 2: Constants / Policies / Logging / Env =====\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "def log(layer: str, msg: str, **kwargs):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "    print(f\"[{layer}] {msg}\")\n",
    "    if kwargs:\n",
    "        for k, v in kwargs.items():\n",
    "            print(f\"  - {k}: {v}\")\n",
    "\n",
    "def now_utc_iso() -> str:\n",
    "    return datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace(\"+00:00\", \"Z\")\n",
    "\n",
    "# .env 로딩 (필요 시)\n",
    "load_dotenv(find_dotenv(), override=False)\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY가 .env에 없습니다.\"\n",
    "log(\"INIT\", \".env loaded\", OPENAI_API_KEY=\"SET\")\n",
    "\n",
    "# 지원 슬롯\n",
    "SLOT_NAMES = [\"electricity_usage\", \"citygas_usage\", \"water_usage\"]\n",
    "\n",
    "# 단위 토큰 표준화(키: 감지 토큰, 값: 표준 단위 문자열)\n",
    "UNIT_TOKENS = {\n",
    "    \"kwh\": \"kWh\", \"mwh\": \"MWh\", \"wh\": \"Wh\",\n",
    "    \"mj\": \"MJ\", \"gj\": \"GJ\",\n",
    "    \"m3\": \"m3\", \"㎥\": \"m3\",\n",
    "    \"tco2e\": \"tCO2e\", \"co2e\": \"tCO2e\",\n",
    "    \"kvarh\": \"kVarh\",\n",
    "}\n",
    "\n",
    "# slotName별 컬럼 패턴\n",
    "PATTERNS_BY_SLOT = {\n",
    "    \"electricity_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"전력\", \"전기사용\", \"usage\", r\"\\bconsumption\\b\", r\"\\bpower\\b\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"kwh\", \"mwh\", \"wh\", \"mj\", \"gj\", \"kvarh\"],\n",
    "    },\n",
    "    \"citygas_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"가스\", \"도시가스\", r\"\\bflow\\b\", r\"\\bvolume\\b\", \"usage\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"m3\", \"㎥\", \"gj\", \"mj\", \"tco2e\", \"co2e\"],\n",
    "    },\n",
    "    \"water_usage\": {\n",
    "        \"date\":  [r\"\\btimestamp\\b\", r\"\\bdatetime\\b\", r\"\\bdate\\b\", r\"\\btime\\b\", \"일시\", \"시각\", \"연월일\", \"년월일\", \"일자\", \"검침일\"],\n",
    "        \"flow\":  [\"사용량\", \"수도\", \"용수\", r\"\\bflow\\b\", r\"\\bvolume\\b\", \"usage\"],\n",
    "        \"cum\":   [\"누적\", \"cumulative\", \"meter\", \"계량\"],\n",
    "        \"unit\":  [r\"\\bunit\\b\", r\"\\buom\\b\", \"단위\", \"m3\", \"㎥\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# slot별 예상 단위\n",
    "EXPECTED_UNITS_BY_SLOT = {\n",
    "    \"electricity_usage\": {\"kWh\"},\n",
    "    \"citygas_usage\": {\"m3\"},\n",
    "    \"water_usage\": {\"m3\"},\n",
    "}\n",
    "\n",
    "# 단위 토큰이 전혀 없을 때 fallback\n",
    "SLOT_DEFAULT_UNIT = {\n",
    "    \"electricity_usage\": \"kWh\",\n",
    "    \"citygas_usage\": \"m3\",\n",
    "    \"water_usage\": \"m3\",\n",
    "}\n",
    "\n",
    "# 최종 표준 컬럼명 규칙\n",
    "SLOT_OUTPUT_SCHEMA = {\n",
    "    \"electricity_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_kwh\",\n",
    "        \"cum\": None,  # 전기는 기본적으로 cum 없음\n",
    "    },\n",
    "    \"citygas_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_m3\",\n",
    "        \"cum\": None,  # 가스는 cum 필수 아님(필요 시 확장 가능)\n",
    "    },\n",
    "    \"water_usage\": {\n",
    "        \"timestamp\": \"timestamp\",\n",
    "        \"flow\": \"flow_m3\",\n",
    "        \"cum\": \"cumulative_meter_m3\",  # 수도는 cum이 있으면 core로 처리 가능\n",
    "    },\n",
    "}\n",
    "\n",
    "# 파싱률 임계치\n",
    "TS_THRESHOLD = 0.95\n",
    "NUM_THRESHOLD = 0.95\n",
    "\n",
    "# 정책\n",
    "FAIL_IF_UNIT_UNRESOLVED = False\n",
    "FAIL_IF_DUP_TS = True\n",
    "\n",
    "# LLM 옵션\n",
    "#USE_LLM = False  # 운영에서는 기본 False, 필요 시 True\n",
    "USE_LLM = True\n",
    "\n",
    "# unit_schema label\n",
    "TIME_UNIT_LABEL = \"time\"\n",
    "UNKNOWN_UNIT_LABEL = \"-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef8de63",
   "metadata": {},
   "source": [
    "### Cell 3 (Utilities): \n",
    "정규표현식 점수 계산(rule_score), 날짜 정규화(normalize_datetime_series) 등 재사용성이 높은 '순수 함수'들의 집합입니다. \n",
    "<br>특히 build_output_schema는 최종 데이터 규격을 통일하는 아주 중요한 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadcbf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 3: Utilities (NO imports, NO constant re-definitions) =====\n",
    "\n",
    "def rule_score(colname: str, patterns: List[str]) -> int:\n",
    "    s = str(colname).lower()\n",
    "    score = 0\n",
    "    for p in patterns:\n",
    "        if p.startswith(r\"\\b\") or \"(\" in p or \"[\" in p:\n",
    "            if re.search(p, s, flags=re.IGNORECASE):\n",
    "                score += 1\n",
    "        else:\n",
    "            if p.lower() in s:\n",
    "                score += 1\n",
    "    return score\n",
    "\n",
    "def parse_rate_numeric(series: pd.Series) -> float:\n",
    "    cleaned = series.astype(str).str.replace(\",\", \"\", regex=False).str.strip()\n",
    "    parsed = pd.to_numeric(cleaned, errors=\"coerce\")\n",
    "    return float(parsed.notna().mean()) if len(parsed) else 0.0\n",
    "\n",
    "def detect_unit_from_name(colname: str) -> Optional[str]:\n",
    "    s = str(colname).lower()\n",
    "    for k, u in UNIT_TOKENS.items():\n",
    "        if k in s:\n",
    "            return u\n",
    "    return None\n",
    "\n",
    "def detect_unit_from_unit_column(unit_series: pd.Series) -> Optional[str]:\n",
    "    values = unit_series.astype(str).str.lower().dropna().tolist()\n",
    "    hits = []\n",
    "    for v in values[:500]:\n",
    "        for k, u in UNIT_TOKENS.items():\n",
    "            if k in v:\n",
    "                hits.append(u)\n",
    "    if not hits:\n",
    "        return None\n",
    "    return pd.Series(hits).mode().iloc[0]\n",
    "\n",
    "def parse_period(period_start: str, period_end: str) -> Tuple[pd.Timestamp, pd.Timestamp]:\n",
    "    ps = pd.to_datetime(period_start, errors=\"raise\").tz_localize(None)\n",
    "    pe = pd.to_datetime(period_end, errors=\"raise\").tz_localize(None)\n",
    "    if pe < ps:\n",
    "        raise ValueError(\"period_end가 period_start보다 빠릅니다.\")\n",
    "    return ps, pe\n",
    "\n",
    "def normalize_datetime_series(raw: pd.Series, period_start: pd.Timestamp) -> Tuple[pd.Series, float, Dict[str, Any], pd.Series]:\n",
    "    s = raw.astype(str).str.strip()\n",
    "\n",
    "    ts1 = pd.to_datetime(s, errors=\"coerce\")\n",
    "    if ts1.dt.tz is not None:\n",
    "        ts1 = ts1.dt.tz_localize(None)\n",
    "\n",
    "    def _fix_one(x: str) -> Optional[pd.Timestamp]:\n",
    "        if x is None: \n",
    "            return None\n",
    "        x = str(x).strip()\n",
    "        if not x:\n",
    "            return None\n",
    "\n",
    "        x2 = (x.replace(\"년\", \"/\").replace(\"월\", \"/\").replace(\"일\", \" \")\n",
    "               .replace(\"시\", \":\").replace(\"분\", \"\"))\n",
    "        x2 = x2.replace(\".\", \"/\").replace(\"-\", \"/\").replace(\",\", \" \")\n",
    "        x2 = re.sub(r\"\\s+\", \" \", x2).strip()\n",
    "\n",
    "        nums = re.findall(r\"\\d+\", x2)\n",
    "        if len(nums) < 2:\n",
    "            return None\n",
    "\n",
    "        if len(nums[0]) == 4:\n",
    "            year = int(nums[0]); idx = 1\n",
    "        else:\n",
    "            year = int(period_start.year); idx = 0\n",
    "\n",
    "        # 간단한 케이스 보정\n",
    "        try:\n",
    "            month = int(nums[idx]); day = int(nums[idx + 1])\n",
    "            hour = int(nums[idx + 2]) if len(nums) >= idx + 3 else 0\n",
    "            minute = int(nums[idx + 3]) if len(nums) >= idx + 4 else 0\n",
    "            if 0 <= hour < 24 and 0 <= minute < 60:\n",
    "                return pd.Timestamp(year=year, month=month, day=day, hour=hour, minute=minute)\n",
    "        except:\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "    ts2 = ts1.copy()\n",
    "    mask_na = ts2.isna()\n",
    "    filled = 0\n",
    "    if mask_na.any():\n",
    "        fixed = s[mask_na].map(_fix_one)\n",
    "        ts2.loc[mask_na] = pd.to_datetime(fixed, errors=\"coerce\")\n",
    "        filled = int(mask_na.sum())\n",
    "\n",
    "    rate = float(ts2.notna().mean()) if len(ts2) else 0.0\n",
    "    normalized_str = ts2.dt.strftime(\"%Y/%m/%d %H:%M\")\n",
    "    debug = {\"parse_rate\": rate, \"filled_from_custom\": filled}\n",
    "    return ts2, rate, debug, normalized_str\n",
    "\n",
    "def detect_time_granularity(ts_parsed: pd.Series) -> Optional[str]:\n",
    "    ts = ts_parsed.dropna().sort_values()\n",
    "    if len(ts) < 3:\n",
    "        return None\n",
    "    deltas = ts.diff().dropna().dt.total_seconds()\n",
    "    if deltas.empty:\n",
    "        return None\n",
    "    mode_sec = float(deltas.mode().iloc[0])\n",
    "\n",
    "    if abs(mode_sec - 600) <= 60: return \"10min\"\n",
    "    if abs(mode_sec - 900) <= 60: return \"15min\"\n",
    "    if abs(mode_sec - 1800) <= 120: return \"30min\"\n",
    "    if abs(mode_sec - 3600) <= 120: return \"hourly\"\n",
    "    if abs(mode_sec - 86400) <= 3600: return \"day\"\n",
    "    if abs(mode_sec - 604800) <= 86400: return \"week\"\n",
    "    return None\n",
    "\n",
    "def granularity_to_pandas_freq(gran: str) -> Optional[str]:\n",
    "    mapping = {\"10min\": \"10min\", \"15min\": \"15min\", \"30min\": \"30min\", \"hourly\": \"h\", \"day\": \"d\"}\n",
    "    return mapping.get(gran)\n",
    "\n",
    "#  validated_fields / unit_schema 생성은 아래 하나로 통일합니다.\n",
    "def build_output_schema(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    date_col: str,\n",
    "    flow_col: str,\n",
    "    cum_col: Optional[str],\n",
    "    resolved_flow_unit: str\n",
    ") -> Tuple[List[str], List[str], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    - core 컬럼: timestamp, flow_*, (cum이 선택되면 cum도 core)\n",
    "    - non-core 컬럼: unit_schema는 무조건 \"-\"\n",
    "    - validated_fields: 최종 출력 컬럼명 리스트\n",
    "    - rename_map: 원본컬럼 -> 최종컬럼명\n",
    "    \"\"\"\n",
    "    schema = SLOT_OUTPUT_SCHEMA[slotName]\n",
    "    rename_map: Dict[str, str] = {}\n",
    "\n",
    "    out_ts = \"timestamp\"\n",
    "    out_flow = schema[\"flow\"]\n",
    "    out_cum = schema.get(\"cum\", None)  # water는 cumulative_meter_m3 가능\n",
    "\n",
    "    # core rename\n",
    "    rename_map[date_col] = out_ts\n",
    "    rename_map[flow_col] = out_flow\n",
    "\n",
    "    cum_is_core = False\n",
    "    if cum_col is not None and out_cum is not None:\n",
    "        rename_map[cum_col] = out_cum\n",
    "        cum_is_core = True\n",
    "\n",
    "    # validated_fields = [core...] + [others...]\n",
    "    validated_fields: List[str] = [out_ts, out_flow]\n",
    "    if cum_is_core:\n",
    "        validated_fields.append(out_cum)\n",
    "\n",
    "    # others keep original names (단, core와 이름 충돌하면 __orig)\n",
    "    reserved = set(validated_fields)\n",
    "    for c in df.columns:\n",
    "        c = str(c)\n",
    "        if c in rename_map:\n",
    "            continue\n",
    "        out_name = c\n",
    "        if out_name in reserved:\n",
    "            out_name = f\"{out_name}__orig\"\n",
    "        rename_map[c] = out_name\n",
    "        reserved.add(out_name)\n",
    "        validated_fields.append(out_name)\n",
    "\n",
    "    # unit_schema 규칙: core만 단위, 나머지는 \"-\"\n",
    "    unit_schema: List[str] = []\n",
    "    for name in validated_fields:\n",
    "        if name == out_ts:\n",
    "            unit_schema.append(TIME_UNIT_LABEL)\n",
    "        elif name == out_flow:\n",
    "            unit_schema.append(resolved_flow_unit)\n",
    "        elif cum_is_core and name == out_cum:\n",
    "            unit_schema.append(\"m3\")\n",
    "        else:\n",
    "            unit_schema.append(UNKNOWN_UNIT_LABEL)\n",
    "\n",
    "    return validated_fields, unit_schema, rename_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc18041",
   "metadata": {},
   "source": [
    "### Cell 4 (Output Helpers): \n",
    "아웃풋 규격(JSON)을 강제합니다. 성공(PASS)과 실패(FAIL)의 구조를 엄격(Strict)하게 유지하여, 프론트엔드나 API 연동 시 에러 발생 가능성을 0으로 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c84771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 4: Strict Output Helpers =====\n",
    "\n",
    "def pass_output_strict(file_path: str, time_granularity: str, unit_schema: list, validated_fields: list):\n",
    "    return {\n",
    "        \"status\": \"PASS\",\n",
    "        \"file_path\": file_path,\n",
    "        \"payload\": {\n",
    "            \"time_granularity\": time_granularity,\n",
    "            \"unit_schema\": unit_schema,\n",
    "            \"validated_fields\": validated_fields\n",
    "        },\n",
    "        \"processed_at\": now_utc_iso()\n",
    "    }\n",
    "\n",
    "def fail_output_strict(file_path: str, code: str, message: str, location: str):\n",
    "    return {\n",
    "        \"status\": \"FAIL\",\n",
    "        \"error\": {\"code\": code, \"message\": message, \"location\": location},\n",
    "        \"file_path\": file_path,\n",
    "        \"processed_at\": now_utc_iso()\n",
    "    }\n",
    "\n",
    "def print_full(result: dict):\n",
    "    print(json.dumps(result, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba8dce8",
   "metadata": {},
   "source": [
    "### Cell 5 (L0): \n",
    "입력 데이터의 '형식'을 검사합니다. 가장 비용이 적게 드는 검증으로, 잘못된 요청을 입구에서 컷트(Cut)합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc18ceaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 5: L0 input sanity =====\n",
    "\n",
    "def layer0_input_sanity(obj: dict) -> Tuple[Optional[dict], Optional[dict]]:\n",
    "    layer = \"L0\"\n",
    "\n",
    "    if not isinstance(obj, dict):\n",
    "        log(layer, \"BAD_INPUT_TYPE\", got=str(type(obj)))\n",
    "        return None, {\"code\":\"BAD_INPUT\", \"message\":\"입력이 dict가 아닙니다.\", \"location\":\"input\"}\n",
    "\n",
    "    required = [\"slotName\", \"kind\", \"ext\", \"period_start\", \"period_end\", \"dataframe\"]\n",
    "    missing = [k for k in required if k not in obj]\n",
    "    if missing:\n",
    "        log(layer, \"MISSING_KEYS\", missing=missing)\n",
    "        return None, {\"code\":\"MISSING_KEYS\", \"message\":f\"필수 키 누락: {missing}\", \"location\":\"input\"}\n",
    "\n",
    "    slot = obj[\"slotName\"]\n",
    "    if slot not in SLOT_NAMES:\n",
    "        log(layer, \"UNKNOWN_SLOT\", slotName=slot)\n",
    "        return None, {\"code\":\"UNKNOWN_SLOT\", \"message\":f\"지원하지 않는 slotName: {slot}\", \"location\":\"input.slotName\"}\n",
    "\n",
    "    df = obj[\"dataframe\"]\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        log(layer, \"BAD_DF_TYPE\", got=str(type(df)))\n",
    "        return None, {\"code\":\"BAD_DF\", \"message\":\"dataframe이 pandas.DataFrame이 아닙니다.\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "    if df.shape[0] < 1 or df.shape[1] < 2:\n",
    "        log(layer, \"NO_DATA\", shape=df.shape)\n",
    "        return None, {\"code\":\"NO_DATA\", \"message\":f\"데이터 행/열이 부족합니다. shape={df.shape}\", \"location\":\"input.dataframe\"}\n",
    "\n",
    "    try:\n",
    "        ps, pe = parse_period(obj[\"period_start\"], obj[\"period_end\"])\n",
    "    except Exception as e:\n",
    "        log(layer, \"BAD_PERIOD\", exc=type(e).__name__)\n",
    "        return None, {\"code\":\"BAD_PERIOD\", \"message\":f\"기간 파싱 실패: {type(e).__name__}\", \"location\":\"input.period_start/end\"}\n",
    "\n",
    "    log(layer, \"PASS\", slotName=slot, shape=df.shape, period_start=str(ps), period_end=str(pe))\n",
    "\n",
    "    normalized = dict(obj)\n",
    "    normalized[\"_period_start_ts\"] = ps\n",
    "    normalized[\"_period_end_ts\"] = pe\n",
    "    return normalized, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c7a0d",
   "metadata": {},
   "source": [
    "### Cell 6 (L1): \n",
    "지저분한 엑셀 데이터를 정제합니다. 특히 strip() 처리 후 중복 컬럼이 발생하는 예외 상황을 잡아내어 데이터 오염을 방지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27cc3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 6: L1 normalize DF (수정본) =====\n",
    "\n",
    "def layer1_normalize_df(df: pd.DataFrame) -> Tuple[Optional[pd.DataFrame], Optional[dict]]:\n",
    "    layer = \"L1\"\n",
    "    df2 = df.copy()\n",
    "    \n",
    "    # 컬럼명의 앞뒤 공백 제거\n",
    "    cols = [str(c).strip() for c in df2.columns]\n",
    "\n",
    "    # 1. 빈 컬럼명 검사\n",
    "    if any(c == \"\" for c in cols):\n",
    "        log(layer, \"EMPTY_COLUMN_NAME\", columns=cols)\n",
    "        return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"빈 컬럼명이 존재합니다(strip 후 '').\", \"location\":\"df.columns\"}\n",
    "\n",
    "    # 2. 중복 컬럼명 검사 (duplicated 함수 추가됨)\n",
    "    if pd.Series(cols).duplicated().any(): \n",
    "        log(layer, \"DUPLICATE_COLUMNS_AFTER_NORMALIZE\", columns=cols)\n",
    "        return None, {\"code\":\"L1_INVALID_COLUMNS\", \"message\":\"L1 정규화 이후 중복 컬럼명이 발생했습니다(strip 후 동일).\", \"location\":\"df.columns\"}\n",
    "\n",
    "    df2.columns = cols\n",
    "    log(layer, \"PASS\", columns=cols)\n",
    "    return df2, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c0bb1",
   "metadata": {},
   "source": [
    "### Cell 7 (LLM Classify): \n",
    "룰 기반으로 찾기 어려운 애매한 컬럼명을 LLM을 통해 분류하는 인터페이스입니다. 현재는 안전하게 비워져(Empty) 있어 시스템 안정성을 높였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6560ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 7: LLM classify (필요시 작동하는 실제 로직) =====\n",
    "from openai import OpenAI\n",
    "\n",
    "def llm_classify_columns_min_tokens(columns: List[str], df: pd.DataFrame, slotName: str) -> dict:\n",
    "    # USE_LLM이 False면 바로 빈 결과 반환 (이중 방어)\n",
    "    if not USE_LLM:\n",
    "        return {\"mapping\": {}}\n",
    "    \n",
    "    # 1. API 클라이언트 초기화 (.env의 키 사용)\n",
    "    client = OpenAI() \n",
    "    \n",
    "    # 2. 토큰 절약 및 보안을 위해 데이터 상단 3줄만 텍스트로 변환\n",
    "    sample_data = df.head(3).to_csv(index=False)\n",
    "    \n",
    "    # 3. 프롬프트 구성: 설명은 배제하고 JSON 결과만 요구 (Strict Output)\n",
    "    prompt = f\"\"\"\n",
    "    Analyze the following CSV columns for a sustainability report ({slotName}).\n",
    "    Columns: {columns}\n",
    "    Sample Data:\n",
    "    {sample_data}\n",
    "    \n",
    "    Identify which column represents:\n",
    "    - 'date': Timestamp or date\n",
    "    - 'flow': Main usage/consumption value\n",
    "    - 'cum': Cumulative meter value (if exists)\n",
    "    - 'unit': Unit of measurement (if exists)\n",
    "    \n",
    "    \"If a column seems to be noise or irrelevant data, map it as 'other' and do not assign it to 'flow' or 'cum'.\"\n",
    "    \n",
    "    Return ONLY a JSON object: {{\"mapping\": {{\"column_name\": \"label\"}}}}\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", # 저렴하고 빠른 모델 권장\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            response_format={ \"type\": \"json_object\" }\n",
    "        )\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except Exception as e:\n",
    "        log(\"LLM_ERROR\", str(e))\n",
    "        return {\"mapping\": {}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9fef04",
   "metadata": {},
   "source": [
    "### Cell 8 (L2: Find Columns): \n",
    "'점수제 -> LLM(선택) -> 값 샘플링(Fallback)'의 3단계 방어 로직을 통해, 어떤 회사 파일이 들어와도 날짜와 사용량 컬럼을 정확히 찾아냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80e27553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 8: L2 find columns =====\n",
    "\n",
    "def layer2_find_columns(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    topn: int = 10,\n",
    "    auto_llm: bool = True,\n",
    "    force_llm: bool = False\n",
    ") -> Tuple[Optional[str], Dict[str, Optional[str]], List[str], Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L2\"\n",
    "    pats = PATTERNS_BY_SLOT[slotName]\n",
    "    cols = [str(c) for c in df.columns]\n",
    "\n",
    "    scored = []\n",
    "    for c in cols:\n",
    "        scored.append((\n",
    "            c,\n",
    "            rule_score(c, pats[\"date\"]),\n",
    "            rule_score(c, pats[\"flow\"]),\n",
    "            rule_score(c, pats[\"unit\"]),\n",
    "            rule_score(c, pats[\"cum\"])\n",
    "        ))\n",
    "\n",
    "    date_candidates = [c for c, sd, _, _, _ in sorted(scored, key=lambda x: x[1], reverse=True)[:topn] if sd > 0]\n",
    "    flow_candidates = [c for c, _, sf, _, _ in sorted(scored, key=lambda x: x[2], reverse=True)[:topn] if sf > 0]\n",
    "    cum_candidates  = [c for c, _, _, _, sc in sorted(scored, key=lambda x: x[4], reverse=True)[:topn] if sc > 0]\n",
    "    unit_cols       = [c for c, _, _, su, _ in scored if su > 0]\n",
    "\n",
    "    debug = {\n",
    "        \"scored_top10\": sorted(scored, key=lambda x: sum(x[1:]), reverse=True)[:10],\n",
    "        \"date_candidates\": date_candidates,\n",
    "        \"flow_candidates\": flow_candidates,\n",
    "        \"cum_candidates\": cum_candidates,\n",
    "        \"unit_cols\": unit_cols,\n",
    "        \"used_llm\": False,\n",
    "        \"llm_reason\": None,\n",
    "        \"llm_raw\": None\n",
    "    }\n",
    "\n",
    "    date_col = date_candidates[0] if date_candidates else None\n",
    "    flow_col = flow_candidates[0] if flow_candidates else None\n",
    "    cum_col  = cum_candidates[0] if cum_candidates else None\n",
    "\n",
    "    # (1) LLM 트리거 판단\n",
    "    need_llm = False\n",
    "    if force_llm:\n",
    "        need_llm = True\n",
    "        debug[\"llm_reason\"] = \"force_llm\"\n",
    "        log(layer, \"AUTO_LLM_TRIGGERED\", reason=\"force_llm\", USE_LLM=USE_LLM)\n",
    "    elif auto_llm and (not date_col or not flow_col):\n",
    "        # 룰이 실패했고, auto_llm 켜져 있으면 LLM을 “시도”할 수 있음\n",
    "        need_llm = True\n",
    "        debug[\"llm_reason\"] = \"rule_missing\"\n",
    "        log(layer, \"AUTO_LLM_TRIGGERED\", reason=\"rule_missing\", USE_LLM=USE_LLM)\n",
    "\n",
    "    # (2) LLM 실행(옵션)\n",
    "    if need_llm and USE_LLM:\n",
    "        debug[\"used_llm\"] = True\n",
    "        llm_res = llm_classify_columns_min_tokens(cols, df, slotName)\n",
    "        debug[\"llm_raw\"] = llm_res\n",
    "\n",
    "        mapping = (llm_res.get(\"mapping\", {}) or {})\n",
    "        date_llm = [c for c, lab in mapping.items() if lab == \"date\" and c in cols]\n",
    "        flow_llm = [c for c, lab in mapping.items() if lab == \"flow\" and c in cols]\n",
    "        cum_llm  = [c for c, lab in mapping.items() if lab == \"cum\" and c in cols]\n",
    "        unit_llm = [c for c, lab in mapping.items() if lab == \"unit\" and c in cols]\n",
    "\n",
    "        date_col = date_col or (date_llm[0] if date_llm else None)\n",
    "        flow_col = flow_col or (flow_llm[0] if flow_llm else None)\n",
    "        cum_col  = cum_col  or (cum_llm[0] if cum_llm else None)\n",
    "        unit_cols = list(set(unit_cols + unit_llm))\n",
    "\n",
    "    # (3) fallback: 값 형태로 찾기\n",
    "    if not date_col:\n",
    "        date_rates = sorted(\n",
    "            [(c, float(pd.to_datetime(df[c], errors=\"coerce\").notna().mean())) for c in cols],\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )\n",
    "        debug[\"date_fallback_top5\"] = date_rates[:5]\n",
    "        date_col = date_rates[0][0] if (date_rates and date_rates[0][1] >= TS_THRESHOLD) else None\n",
    "\n",
    "    if not flow_col:\n",
    "        val_rates = sorted([(c, parse_rate_numeric(df[c])) for c in cols], key=lambda x: x[1], reverse=True)\n",
    "        debug[\"flow_fallback_top5\"] = val_rates[:5]\n",
    "        flow_col = val_rates[0][0] if (val_rates and val_rates[0][1] >= NUM_THRESHOLD) else None\n",
    "\n",
    "    if not date_col or not flow_col:\n",
    "        return None, {\"flow\": None, \"cum\": None}, unit_cols, {\n",
    "            \"code\":\"REQUIRED_FIELD_NOT_FOUND\",\n",
    "            \"message\":\"필수 컬럼(date/flow)을 찾지 못했습니다.\",\n",
    "            \"location\":\"columns\"\n",
    "        }, debug\n",
    "\n",
    "    log(layer, \"picked\", date_col=date_col, flow_col=flow_col, cum_col=cum_col, unit_cols=unit_cols)\n",
    "    return date_col, {\"flow\": flow_col, \"cum\": cum_col}, unit_cols, None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fcf368",
   "metadata": {},
   "source": [
    "### Cell 9 (L3: Value Validation): \n",
    "데이터 값이 진짜 숫자인지, 날짜인지 정밀 검사합니다. 특히 resolved_unit을 통해 잘못된 단위(ex. 전기인데 m3)가 들어오는 것을 차단합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969e69c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 9: L3 validate values =====\n",
    "\n",
    "def layer3_validate_values(\n",
    "    df: pd.DataFrame,\n",
    "    slotName: str,\n",
    "    date_col: str,\n",
    "    value_cols: Dict[str, Optional[str]],\n",
    "    unit_cols: List[str],\n",
    "    period_start: pd.Timestamp\n",
    ") -> Tuple[Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L3\"\n",
    "    debug: Dict[str, Any] = {}\n",
    "\n",
    "    flow_col = value_cols[\"flow\"]\n",
    "\n",
    "    ts_parsed, ts_rate, ts_dbg, ts_norm_str = normalize_datetime_series(df[date_col], period_start=period_start)\n",
    "    flow_num_rate = parse_rate_numeric(df[flow_col])\n",
    "\n",
    "    time_gran = detect_time_granularity(ts_parsed)\n",
    "\n",
    "    debug[\"ts_rate\"] = ts_rate\n",
    "    debug[\"flow_num_rate\"] = flow_num_rate\n",
    "    debug[\"time_granularity\"] = time_gran\n",
    "\n",
    "    if ts_rate < TS_THRESHOLD:\n",
    "        return {\"code\":\"TS_PARSE_LOW\", \"message\":f\"날짜 파싱률 낮음(ts_rate={ts_rate:.2f})\", \"location\":f\"col:{date_col}\"}, debug\n",
    "    if flow_num_rate < NUM_THRESHOLD:\n",
    "        return {\"code\":\"VALUE_PARSE_LOW\", \"message\":f\"숫자 파싱률 낮음(num_rate={flow_num_rate:.2f})\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "    if time_gran is None:\n",
    "        return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도 판별 불가\", \"location\":f\"col:{date_col}\"}, debug\n",
    "\n",
    "    # 단위 결정\n",
    "    resolved_unit = None\n",
    "\n",
    "    # 1) unit 컬럼이 있으면 그 값에서 탐지\n",
    "    for uc in unit_cols or []:\n",
    "        u = detect_unit_from_unit_column(df[uc])\n",
    "        if u:\n",
    "            resolved_unit = u\n",
    "            break\n",
    "\n",
    "    # 2) flow 컬럼명에서 탐지 (Usage_kWh 같은 케이스)\n",
    "    if resolved_unit is None:\n",
    "        u = detect_unit_from_name(flow_col)\n",
    "        if u:\n",
    "            resolved_unit = u\n",
    "\n",
    "    # 3) slot 기본 단위 fallback\n",
    "    if resolved_unit is None:\n",
    "        if FAIL_IF_UNIT_UNRESOLVED:\n",
    "            return {\"code\":\"UNIT_UNRESOLVED\", \"message\":\"단위 판별 불가\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "        resolved_unit = SLOT_DEFAULT_UNIT[slotName]\n",
    "\n",
    "    expected_units = EXPECTED_UNITS_BY_SLOT[slotName]\n",
    "    if resolved_unit not in expected_units:\n",
    "        return {\n",
    "            \"code\":\"UNIT_MISMATCH\",\n",
    "            \"message\":f\"단위 불일치: got={resolved_unit}, expected={list(expected_units)[0]}\",\n",
    "            \"location\":f\"col:{flow_col}\"\n",
    "        }, debug\n",
    "\n",
    "    debug[\"_ts_parsed\"] = ts_parsed\n",
    "    debug[\"resolved_unit\"] = resolved_unit\n",
    "    return None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9b9ec8",
   "metadata": {},
   "source": [
    "### Cell 10 (L4: Period Coverage): \n",
    "가장 까다로운 단계입니다. 1시간 간격 데이터인데 12시 데이터가 없다면 바로 잡아냅니다. 환경 공시 보고서의 신뢰도를 결정짓는 핵심 셀입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e29e5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 10: L4 period coverage =====\n",
    "\n",
    "def granularity_to_pandas_freq(gran: str) -> Optional[str]:\n",
    "    mapping = {\"10min\": \"10min\", \"15min\": \"15min\", \"30min\": \"30min\", \"hourly\": \"h\", \"day\": \"d\"}\n",
    "    return mapping.get(gran)\n",
    "\n",
    "def align_ts_for_compare(ts: pd.Series, gran: str) -> pd.Series:\n",
    "    if gran in (\"10min\", \"15min\", \"30min\"):\n",
    "        mins = int(gran.replace(\"min\", \"\"))\n",
    "        return ts.dt.floor(f\"{mins}min\")\n",
    "    if gran == \"hourly\":\n",
    "        return ts.dt.floor(\"h\")\n",
    "    if gran == \"day\":\n",
    "        return ts.dt.floor(\"d\")\n",
    "    return ts\n",
    "\n",
    "def layer4_validate_period_coverage(\n",
    "    df: pd.DataFrame,\n",
    "    ts_parsed: pd.Series,\n",
    "    flow_col: str,\n",
    "    period_start: pd.Timestamp,\n",
    "    period_end: pd.Timestamp,\n",
    "    granularity: str\n",
    ") -> Tuple[Optional[dict], dict]:\n",
    "\n",
    "    layer = \"L4\"\n",
    "    debug: Dict[str, Any] = {}\n",
    "\n",
    "    ts_aligned = align_ts_for_compare(ts_parsed, granularity)\n",
    "\n",
    "    mask = (ts_aligned >= period_start) & (ts_aligned <= period_end)\n",
    "    df_in = df.loc[mask].copy()\n",
    "    ts_in = ts_aligned.loc[mask]\n",
    "\n",
    "    debug[\"rows_in_period\"] = int(df_in.shape[0])\n",
    "    if df_in.shape[0] == 0:\n",
    "        return {\"code\":\"PERIOD_OUT_OF_RANGE\", \"message\":\"지정 기간 내 데이터가 없습니다.\", \"location\":\"period\"}, debug\n",
    "\n",
    "    dup_count = int(pd.Series(ts_in.dropna().values).duplicated().sum())\n",
    "    debug[\"duplicate_ts_count\"] = dup_count\n",
    "    if FAIL_IF_DUP_TS and dup_count > 0:\n",
    "        return {\"code\":\"DUPLICATE_TIMESTAMPS\", \"message\":\"기간 내 중복 timestamp 존재\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "    freq = granularity_to_pandas_freq(granularity)\n",
    "    if freq is None:\n",
    "        return {\"code\":\"TIME_GRAIN_UNKNOWN\", \"message\":\"시간 해상도 판별 불가(L4)\", \"location\":\"time_granularity\"}, debug\n",
    "\n",
    "    expected = pd.date_range(start=period_start, end=period_end, freq=freq)\n",
    "    exp_set = set(expected.tolist())\n",
    "    act_set = set(ts_in.dropna().tolist())\n",
    "\n",
    "    missing = sorted(list(exp_set - act_set))\n",
    "    if missing:\n",
    "        return {\"code\":\"PERIOD_MISSING_TIMESTAMPS\", \"message\":\"기간 내 timestamp 누락\", \"location\":\"timestamp\"}, debug\n",
    "\n",
    "    val_num = pd.to_numeric(df_in[flow_col].astype(str).str.replace(\",\", \"\", regex=False).str.strip(), errors=\"coerce\")\n",
    "    if int(val_num.isna().sum()) > 0:\n",
    "        return {\"code\":\"PERIOD_VALUE_MISSING\", \"message\":\"기간 내 flow 값 누락\", \"location\":f\"col:{flow_col}\"}, debug\n",
    "\n",
    "    log(layer, \"PASS\", rows_in_period=debug[\"rows_in_period\"])\n",
    "    return None, debug\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d74163",
   "metadata": {},
   "source": [
    "### [Cell 11] 메인 오케스트레이터 (validate_structured_upstream)\n",
    "L0부터 L4까지의 모든 셀을 순서대로 실행하며 결과를 조합합니다. 각 레이어의 리턴값을 체크하여 중간에 문제가 생기면 즉시 중단(Abort)하고 에러를 리포팅하는 지휘자 역할을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e062c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 11 validate_structured_upstream =====\n",
    "\n",
    "\n",
    "def validate_structured_upstream(obj: dict, file_path: str = \"upstream.xlsx\"):\n",
    "    log(\"MAIN\", \"start\", slotName=obj.get(\"slotName\"), file_path=file_path)\n",
    "\n",
    "    # L0\n",
    "    norm, err0 = layer0_input_sanity(obj)\n",
    "    if err0:\n",
    "        return fail_output_strict(file_path, err0[\"code\"], err0[\"message\"], err0[\"location\"])\n",
    "\n",
    "    slotName = norm[\"slotName\"]\n",
    "    df_raw = norm[\"dataframe\"]\n",
    "    ps, pe = norm[\"_period_start_ts\"], norm[\"_period_end_ts\"]\n",
    "\n",
    "    # L1\n",
    "    df, err1 = layer1_normalize_df(df_raw)\n",
    "    if err1:\n",
    "        return fail_output_strict(file_path, err1[\"code\"], err1[\"message\"], err1[\"location\"])\n",
    "\n",
    "    # L2\n",
    "    date_col, value_cols, unit_cols, err2, _ = layer2_find_columns(df, slotName=slotName)\n",
    "    if err2:\n",
    "        return fail_output_strict(file_path, err2[\"code\"], err2[\"message\"], err2[\"location\"])\n",
    "\n",
    "    # L3\n",
    "    err3, dbg3 = layer3_validate_values(df, slotName, date_col, value_cols, unit_cols, ps)\n",
    "    if err3:\n",
    "        return fail_output_strict(file_path, err3[\"code\"], err3[\"message\"], err3[\"location\"])\n",
    "\n",
    "    # L4\n",
    "    err4, _ = layer4_validate_period_coverage(df, dbg3[\"_ts_parsed\"], value_cols[\"flow\"], ps, pe, dbg3[\"time_granularity\"])\n",
    "    if err4:\n",
    "        return fail_output_strict(file_path, err4[\"code\"], err4[\"message\"], err4[\"location\"])\n",
    "\n",
    "    # 여기서 output 스키마/단위 스키마를 \"하나의 함수\"로 통일 생성\n",
    "    validated_fields, unit_schema, rename_map = build_output_schema(\n",
    "        df=df,\n",
    "        slotName=slotName,\n",
    "        date_col=date_col,\n",
    "        flow_col=value_cols[\"flow\"],\n",
    "        cum_col=value_cols.get(\"cum\"),\n",
    "        resolved_flow_unit=dbg3[\"resolved_unit\"]\n",
    "    )\n",
    "\n",
    "    payload_time_gran = dbg3[\"time_granularity\"]\n",
    "    return pass_output_strict(file_path, payload_time_gran, unit_schema, validated_fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24e68c",
   "metadata": {},
   "source": [
    "### 테스트 셀들(12~19)\n",
    "Cell 12 — 테스트 데이터 생성기(현실성 + 규모) <br>\n",
    "역할: \n",
    "전기(15분, 8832행), 가스/수도(시간, 2208행) 같은 현실적 규모로 df를 만든다.<br>\n",
    "“파일 I/O 없이도” 파이프라인 검증 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c7bd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 12: Test data generators =====\n",
    "\n",
    "def make_ts_range(period_start: str, period_end: str, freq: str) -> pd.DatetimeIndex:\n",
    "    ps = pd.to_datetime(period_start)\n",
    "    pe = pd.to_datetime(period_end)\n",
    "    return pd.date_range(ps, pe, freq=freq)\n",
    "\n",
    "def gen_electricity_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"15min\")\n",
    "    n = len(ts)\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": ts,\n",
    "        \"Usage_kWh\": np.round(np.random.uniform(50, 180, n), 3),\n",
    "        \"Lagging_Current_Reactive.Power_kVarh\": np.round(np.random.uniform(0, 30, n), 3),\n",
    "        \"Leading_Current_Reactive_Power_kVarh\": np.round(np.random.uniform(0, 30, n), 3),\n",
    "        \"Lagging_Current_Power_Factor\": np.round(np.random.uniform(0.7, 1.0, n), 3),\n",
    "        \"Leading_Current_Power_Factor\": np.round(np.random.uniform(0.7, 1.0, n), 3),\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def gen_water_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"h\")\n",
    "    n = len(ts)\n",
    "    flow = np.round(np.random.uniform(5, 40, n), 3)\n",
    "    cum = np.round(np.cumsum(flow), 3)\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        \"flow_m3\": flow,\n",
    "        \"cumulative_meter_m3\": cum\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def gen_citygas_df(period_start: str, period_end: str) -> pd.DataFrame:\n",
    "    ts = make_ts_range(period_start, period_end, \"h\")\n",
    "    n = len(ts)\n",
    "    flow = np.round(np.random.uniform(10, 60, n), 3)\n",
    "    calorific = np.round(np.random.uniform(38, 43, n), 3)  # MJ/m3 근사\n",
    "    energy = np.round(flow * calorific, 3)                  # MJ\n",
    "    co2e = np.round(energy * 0.000056, 6)                   # 임의 계수(테스트용)\n",
    "    df = pd.DataFrame({\n",
    "        \"timestamp\": ts,\n",
    "        \"flow_m3\": flow,\n",
    "        \"calorific_MJ_per_m3\": calorific,\n",
    "        \"energy_MJ\": energy,\n",
    "        \"CO2e_t\": co2e,\n",
    "    })\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aace92",
   "metadata": {},
   "source": [
    "Cell 13 — PASS 테스트 3종(전기/수도/가스)\n",
    "역할\n",
    "\n",
    "“실제 운영 성공 케이스” 3개를 한 번에 보여줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532f60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REAL-FILE TEST] 검증 시작: 2026-01-21T02:44:55Z\n",
      "------------------------------------------------------------\n",
      "\n",
      "[PROCESSING] 전기요금 (성광벤드_전기요금_2025년_4분기.xlsx) 검사 중...\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: 성광벤드_전기요금_2025년_4분기.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (8832, 6)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 23:59:59\n",
      "[L1] PASS\n",
      "  - columns: ['date', 'Usage_kWh', 'Lagging_Current_Reactive.Power_kVarh', 'Leading_Current_Reactive_Power_kVarh', 'Lagging_Current_Power_Factor', 'Leading_Current_Power_Factor']\n",
      "[L2] picked\n",
      "  - date_col: date\n",
      "  - flow_col: Usage_kWh\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['Usage_kWh', 'Lagging_Current_Reactive.Power_kVarh', 'Leading_Current_Reactive_Power_kVarh']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 8832\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_전기요금_2025년_4분기.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"15min\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"kWh\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_kwh\",\n",
      "      \"Lagging_Current_Reactive.Power_kVarh\",\n",
      "      \"Leading_Current_Reactive_Power_kVarh\",\n",
      "      \"Lagging_Current_Power_Factor\",\n",
      "      \"Leading_Current_Power_Factor\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T02:44:56Z\"\n",
      "}\n",
      "전기요금: 모든 품질 게이트 통과 (PASS)\n",
      "\n",
      "[PROCESSING] 수도요금 (성광벤드_수도요금_2025년_4분기.xlsx) 검사 중...\n",
      "[MAIN] start\n",
      "  - slotName: water_usage\n",
      "  - file_path: 성광벤드_수도요금_2025년_4분기.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: water_usage\n",
      "  - shape: (2208, 3)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 23:59:59\n",
      "[L1] PASS\n",
      "  - columns: ['timestamp', 'flow_m3', 'cumulative_meter_m3']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[L2] picked\n",
      "  - date_col: timestamp\n",
      "  - flow_col: flow_m3\n",
      "  - cum_col: cumulative_meter_m3\n",
      "  - unit_cols: ['flow_m3', 'cumulative_meter_m3']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 2208\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_수도요금_2025년_4분기.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"hourly\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"m3\",\n",
      "      \"m3\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_m3\",\n",
      "      \"cumulative_meter_m3\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T02:44:58Z\"\n",
      "}\n",
      "수도요금: 모든 품질 게이트 통과 (PASS)\n",
      "\n",
      "[PROCESSING] 도시가스요금 (성광벤드_도시가스요금_2025년_4분기.xlsx) 검사 중...\n",
      "[MAIN] start\n",
      "  - slotName: citygas_usage\n",
      "  - file_path: 성광벤드_도시가스요금_2025년_4분기.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: citygas_usage\n",
      "  - shape: (2208, 5)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 23:59:59\n",
      "[L1] PASS\n",
      "  - columns: ['timestamp', 'flow_m3', 'calorific_MJ_per_m3', 'energy_MJ', 'CO2e_t']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[L2] picked\n",
      "  - date_col: timestamp\n",
      "  - flow_col: flow_m3\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['energy_MJ', 'flow_m3', 'CO2e_t', 'calorific_MJ_per_m3']\n",
      "[L4] PASS\n",
      "  - rows_in_period: 2208\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"성광벤드_도시가스요금_2025년_4분기.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"hourly\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"m3\",\n",
      "      \"-\",\n",
      "      \"-\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_m3\",\n",
      "      \"calorific_MJ_per_m3\",\n",
      "      \"energy_MJ\",\n",
      "      \"CO2e_t\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T02:45:02Z\"\n",
      "}\n",
      "도시가스요금: 모든 품질 게이트 통과 (PASS)\n",
      "\n",
      "============================================================\n",
      "[TEST FINISHED] 완료 시각: 2026-01-21T02:45:02Z\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 13: Real File Validation (Path Adjusted) =====\n",
    "\n",
    "# 1. 경로 설정 (노트북 파일 위치인 notebooks/ 에서 상위로 이동 후 data/samples/E/ 로 접근)\n",
    "BASE_DATA_PATH = \"../data/samples/E\"\n",
    "\n",
    "test_configs = [\n",
    "    {\n",
    "        \"slot\": \"electricity_usage\",\n",
    "        \"file_name\": \"성광벤드_전기요금_2025년_4분기.xlsx\",\n",
    "        \"label\": \"전기요금\"\n",
    "    },\n",
    "    {\n",
    "        \"slot\": \"water_usage\",\n",
    "        \"file_name\": \"성광벤드_수도요금_2025년_4분기.xlsx\",\n",
    "        \"label\": \"수도요금\"\n",
    "    },\n",
    "    {\n",
    "        \"slot\": \"citygas_usage\",\n",
    "        \"file_name\": \"성광벤드_도시가스요금_2025년_4분기.xlsx\",\n",
    "        \"label\": \"도시가스요금\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2025년 4분기 표준 기간 설정 (사용자 요청 기간 반영)\n",
    "# 데이터의 마지막 시각이 00:00일 경우와 23:59일 경우를 대비해 설정 확인 필요\n",
    "PERIOD_START = \"2025-10-01T00:00:00\"\n",
    "PERIOD_END   = \"2025-12-31T23:59:59\"\n",
    "\n",
    "print(f\"[REAL-FILE TEST] 검증 시작: {now_utc_iso()}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for config in test_configs:\n",
    "    full_path = os.path.join(BASE_DATA_PATH, config[\"file_name\"])\n",
    "    label = config[\"label\"]\n",
    "    \n",
    "    print(f\"\\n[PROCESSING] {label} ({config['file_name']}) 검사 중...\")\n",
    "    \n",
    "    # [Step 1] 파일 존재 여부 확인\n",
    "    if not os.path.exists(full_path):\n",
    "        print(f\"  에러: 파일을 찾을 수 없습니다. 경로: {full_path}\")\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        # [Step 2] pandas 데이터 로드\n",
    "        raw_df = pd.read_excel(full_path)\n",
    "        \n",
    "        # [Step 3] 검증용 입력 객체(obj) 생성\n",
    "        obj = {\n",
    "            \"slotName\": config[\"slot\"],\n",
    "            \"kind\": \"EXCEL\",\n",
    "            \"ext\": \"xlsx\",\n",
    "            \"period_start\": PERIOD_START,\n",
    "            \"period_end\": PERIOD_END,\n",
    "            \"dataframe\": raw_df\n",
    "        }\n",
    "        \n",
    "        # [Step 4] 메인 검증 파이프라인(L0~L4) 실행\n",
    "        res = validate_structured_upstream(obj, file_path=config[\"file_name\"])\n",
    "        \n",
    "        # [Step 5] Cell 4의 헬퍼를 통한 결과 출력\n",
    "        print_full(res)\n",
    "        \n",
    "        # 결과 요약 리포트\n",
    "        if res[\"status\"] == \"PASS\":\n",
    "            print(f\"{label}: 모든 품질 게이트 통과 (PASS)\")\n",
    "        else:\n",
    "            err = res.get(\"error\", {})\n",
    "            print(f\"{label}: 검증 실패 (FAIL)\")\n",
    "            print(f\"     - 사유: {err.get('code')} / {err.get('message')}\")\n",
    "            print(f\"     - 위치: {err.get('location')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{label}: 런타임 오류 발생 -> {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"[TEST FINISHED] 완료 시각: {now_utc_iso()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403be530",
   "metadata": {},
   "source": [
    "Cell 14 — FAIL(L0) 테스트 2종\n",
    "역할\n",
    "\n",
    "입력 단계에서 FAIL이 제대로 발생하는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0e01a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L0 - MISSING_KEYS ===\n",
      "[MAIN] start\n",
      "  - slotName: None\n",
      "  - file_path: L0_missing_keys.xlsx\n",
      "[L0] MISSING_KEYS\n",
      "  - missing: ['slotName']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"MISSING_KEYS\",\n",
      "    \"message\": \"필수 키 누락: ['slotName']\",\n",
      "    \"location\": \"input\"\n",
      "  },\n",
      "  \"file_path\": \"L0_missing_keys.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:02Z\"\n",
      "}\n",
      "\n",
      "=== [FAIL 기대] L0 - BAD_DF ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L0_bad_df.xlsx\n",
      "[L0] BAD_DF_TYPE\n",
      "  - got: <class 'str'>\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"BAD_DF\",\n",
      "    \"message\": \"dataframe이 pandas.DataFrame이 아닙니다.\",\n",
      "    \"location\": \"input.dataframe\"\n",
      "  },\n",
      "  \"file_path\": \"L0_bad_df.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:02Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 14: FAIL tests - L0 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L0 - MISSING_KEYS ===\")\n",
    "obj = {\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":pd.DataFrame({\"a\":[1],\"b\":[2]})}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L0_missing_keys.xlsx\"))\n",
    "\n",
    "print(\"\\n=== [FAIL 기대] L0 - BAD_DF ===\")\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":\"NOT_DF\"}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L0_bad_df.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff89f19",
   "metadata": {},
   "source": [
    "Cell 15 — FAIL(L1) 중복/빈 컬럼명\n",
    "역할\n",
    "\n",
    "L1 품질 게이트(중복/빈 컬럼명)가 실제로 FAIL을 만드는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "febedf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L1 - 중복 컬럼명(strip 후 동일) ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L1_dup_cols.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (10, 3)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 23:59:59\n",
      "[L1] DUPLICATE_COLUMNS_AFTER_NORMALIZE\n",
      "  - columns: ['A', 'A', 'B']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"L1_INVALID_COLUMNS\",\n",
      "    \"message\": \"L1 정규화 이후 중복 컬럼명이 발생했습니다(strip 후 동일).\",\n",
      "    \"location\": \"df.columns\"\n",
      "  },\n",
      "  \"file_path\": \"L1_dup_cols.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:02Z\"\n",
      "}\n",
      "\n",
      "=== [FAIL 기대] L1 - 빈 컬럼명 ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L1_empty_col.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (10, 2)\n",
      "  - period_start: 2025-10-01 00:00:00\n",
      "  - period_end: 2025-12-31 23:59:59\n",
      "[L1] EMPTY_COLUMN_NAME\n",
      "  - columns: ['', 'B']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"L1_INVALID_COLUMNS\",\n",
      "    \"message\": \"빈 컬럼명이 존재합니다(strip 후 '').\",\n",
      "    \"location\": \"df.columns\"\n",
      "  },\n",
      "  \"file_path\": \"L1_empty_col.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:02Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 15: FAIL tests - L1 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L1 - 중복 컬럼명(strip 후 동일) ===\")\n",
    "df = pd.DataFrame({\"A\":[1]*10, \" A \":[2]*10, \"B\":[3]*10})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L1_dup_cols.xlsx\"))\n",
    "\n",
    "print(\"\\n=== [FAIL 기대] L1 - 빈 컬럼명 ===\")\n",
    "df = pd.DataFrame({\"\":[1]*10, \"B\":[2]*10})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":PERIOD_START,\"period_end\":PERIOD_END,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L1_empty_col.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f09fa",
   "metadata": {},
   "source": [
    "Cell 16 — FAIL(L2) 필수 컬럼 탐지 실패\n",
    "역할\n",
    "\n",
    "L2에서 date/flow 후보를 못 찾으면 REQUIRED_FIELD_NOT_FOUND로 FAIL 나는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6769530f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L2 - REQUIRED_FIELD_NOT_FOUND ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L2_required_not_found.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (480, 3)\n",
      "  - period_start: 2026-02-01 00:00:00\n",
      "  - period_end: 2026-02-05 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['비정상_날짜필드', '알수없는_수치', '메모']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[L2] picked\n",
      "  - date_col: 비정상_날짜필드\n",
      "  - flow_col: 알수없는_수치\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"TS_PARSE_LOW\",\n",
      "    \"message\": \"날짜 파싱률 낮음(ts_rate=0.00)\",\n",
      "    \"location\": \"col:비정상_날짜필드\"\n",
      "  },\n",
      "  \"file_path\": \"L2_required_not_found.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:04Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 16: FAIL tests - L2 =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L2 - REQUIRED_FIELD_NOT_FOUND ===\")\n",
    "df = pd.DataFrame({\n",
    "    \"비정상_날짜필드\": [\"x\"]*480,\n",
    "    \"알수없는_수치\": [\"foo\"]*480,\n",
    "    \"메모\": [\"memo\"]*480\n",
    "})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":\"2026-02-01T00:00:00\",\"period_end\":\"2026-02-05T23:45:00\",\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L2_required_not_found.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e416d2",
   "metadata": {},
   "source": [
    "Cell 17 — FAIL(L3) 단위 불일치(전기인데 m3)\n",
    "역할\n",
    "\n",
    "L3에서 단위 mismatch가 제대로 FAIL 처리되는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f17872c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L3 - UNIT_MISMATCH ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L3_unit_mismatch.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (1344, 3)\n",
      "  - period_start: 2026-01-10 00:00:00\n",
      "  - period_end: 2026-01-23 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['일시', '사용량(m3)', '비고']\n",
      "[L2] picked\n",
      "  - date_col: 일시\n",
      "  - flow_col: 사용량(m3)\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"UNIT_MISMATCH\",\n",
      "    \"message\": \"단위 불일치: got=m3, expected=kWh\",\n",
      "    \"location\": \"col:사용량(m3)\"\n",
      "  },\n",
      "  \"file_path\": \"L3_unit_mismatch.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:04Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 17: FAIL tests - L3 (UNIT_MISMATCH) =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L3 - UNIT_MISMATCH ===\")\n",
    "ts = pd.date_range(\"2026-01-10 00:00:00\", \"2026-01-23 23:45:00\", freq=\"15min\")\n",
    "df = pd.DataFrame({\n",
    "    \"일시\": ts,\n",
    "    \"사용량(m3)\": np.round(np.random.uniform(10, 60, len(ts)), 3),  # 전기인데 m3로 들어온 케이스\n",
    "    \"비고\": [\"x\"]*len(ts)\n",
    "})\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":\"2026-01-10T00:00:00\",\"period_end\":\"2026-01-23T23:45:00\",\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L3_unit_mismatch.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a804f",
   "metadata": {},
   "source": [
    "Cell 18 — FAIL(L4) 기간 내 timestamp 1개 누락\n",
    "역할\n",
    "\n",
    "L4에서 “기간 커버리지 100%”가 실제로 강제되는지 증명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554fe7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [FAIL 기대] L4 - PERIOD_MISSING_TIMESTAMPS ===\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: L4_missing_timestamp.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (767, 3)\n",
      "  - period_start: 2026-01-24 00:00:00\n",
      "  - period_end: 2026-01-31 23:45:00\n",
      "[L1] PASS\n",
      "  - columns: ['일시', '사용량(kWh)', '역률']\n",
      "[L2] picked\n",
      "  - date_col: 일시\n",
      "  - flow_col: 사용량(kWh)\n",
      "  - cum_col: None\n",
      "  - unit_cols: ['사용량(kWh)']\n",
      "{\n",
      "  \"status\": \"FAIL\",\n",
      "  \"error\": {\n",
      "    \"code\": \"PERIOD_MISSING_TIMESTAMPS\",\n",
      "    \"message\": \"기간 내 timestamp 누락\",\n",
      "    \"location\": \"timestamp\"\n",
      "  },\n",
      "  \"file_path\": \"L4_missing_timestamp.xlsx\",\n",
      "  \"processed_at\": \"2026-01-21T02:45:04Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 18: FAIL tests - L4 (missing timestamp) =====\n",
    "\n",
    "print(\"=== [FAIL 기대] L4 - PERIOD_MISSING_TIMESTAMPS ===\")\n",
    "ps = \"2026-01-24T00:00:00\"\n",
    "pe = \"2026-01-31T23:45:00\"\n",
    "ts = pd.date_range(pd.to_datetime(ps), pd.to_datetime(pe), freq=\"15min\")\n",
    "df = pd.DataFrame({\n",
    "    \"일시\": ts,\n",
    "    \"사용량(kWh)\": np.round(np.random.uniform(50, 180, len(ts)), 3),\n",
    "    \"역률\": np.round(np.random.uniform(0.7, 1.0, len(ts)), 3),\n",
    "})\n",
    "df = df.drop(index=100).reset_index(drop=True)  # timestamp 1개 제거\n",
    "obj = {\"slotName\":\"electricity_usage\",\"kind\":\"EXCEL\",\"ext\":\"xlsx\",\"period_start\":ps,\"period_end\":pe,\"dataframe\":df}\n",
    "print_full(validate_structured_upstream(obj, file_path=\"L4_missing_timestamp.xlsx\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca5dca3",
   "metadata": {},
   "source": [
    "Cell 20 - 테스트용 셀 (19보다 먼저 실행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e78200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Cell 20: LLM Stub/Spy utilities =====\n",
    "\n",
    "_LLM_ORIG_FUNCS = {}\n",
    "_LLM_STUB_INSTALLED = False\n",
    "_LLM_SPY_INSTALLED = False\n",
    "\n",
    "_LLM_CALL_COUNTER = {\"n\": 0}\n",
    "\n",
    "def llm_calls() -> int:\n",
    "    return int(_LLM_CALL_COUNTER[\"n\"])\n",
    "\n",
    "def reset_llm_calls():\n",
    "    _LLM_CALL_COUNTER[\"n\"] = 0\n",
    "\n",
    "def install_llm_stub(mapping: dict, llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    llm_classify_columns_min_tokens를 스텁으로 바꿔서\n",
    "    항상 {\"mapping\": mapping}을 반환하게 함.\n",
    "    - mapping 예: {\"A\":\"date\",\"B\":\"flow\",\"C\":\"other\"}\n",
    "    \"\"\"\n",
    "    global _LLM_STUB_INSTALLED\n",
    "\n",
    "    if llm_func_name not in globals():\n",
    "        raise NameError(f\"{llm_func_name} is not defined in globals(). 먼저 Cell 7(LLM 함수) 정의를 확인하세요.\")\n",
    "\n",
    "    if llm_func_name not in _LLM_ORIG_FUNCS:\n",
    "        _LLM_ORIG_FUNCS[llm_func_name] = globals()[llm_func_name]\n",
    "\n",
    "    def _stub(columns, df, slotName):\n",
    "        _LLM_CALL_COUNTER[\"n\"] += 1\n",
    "        log(\"LLM_STUB\", \"CALLED\", n=_LLM_CALL_COUNTER[\"n\"], slotName=slotName, columns=len(columns))\n",
    "        # 스텁은 무조건 매핑만 반환(설명 문장 X)\n",
    "        return {\"mapping\": dict(mapping)}\n",
    "\n",
    "    globals()[llm_func_name] = _stub\n",
    "    _LLM_STUB_INSTALLED = True\n",
    "    print(\"LLM stub installed.\")\n",
    "\n",
    "def install_llm_spy(llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    실제 llm_classify_columns_min_tokens 호출 횟수만 체크하는 spy.\n",
    "    (원본을 감싸서 counter만 증가)\n",
    "    \"\"\"\n",
    "    global _LLM_SPY_INSTALLED\n",
    "\n",
    "    if llm_func_name not in globals():\n",
    "        raise NameError(f\"{llm_func_name} is not defined in globals().\")\n",
    "\n",
    "    if llm_func_name not in _LLM_ORIG_FUNCS:\n",
    "        _LLM_ORIG_FUNCS[llm_func_name] = globals()[llm_func_name]\n",
    "\n",
    "    orig = _LLM_ORIG_FUNCS[llm_func_name]\n",
    "\n",
    "    def _spy(columns, df, slotName):\n",
    "        _LLM_CALL_COUNTER[\"n\"] += 1\n",
    "        log(\"LLM_SPY\", \"CALLED\", n=_LLM_CALL_COUNTER[\"n\"], slotName=slotName, columns=len(columns))\n",
    "        return orig(columns, df, slotName)\n",
    "\n",
    "    globals()[llm_func_name] = _spy\n",
    "    _LLM_SPY_INSTALLED = True\n",
    "    print(\"LLM spy installed.\")\n",
    "\n",
    "def restore_llm(llm_func_name: str = \"llm_classify_columns_min_tokens\"):\n",
    "    \"\"\"\n",
    "    stub/spy로 교체한 함수를 원복\n",
    "    \"\"\"\n",
    "    global _LLM_STUB_INSTALLED, _LLM_SPY_INSTALLED\n",
    "\n",
    "    if llm_func_name in _LLM_ORIG_FUNCS:\n",
    "        globals()[llm_func_name] = _LLM_ORIG_FUNCS[llm_func_name]\n",
    "        del _LLM_ORIG_FUNCS[llm_func_name]\n",
    "\n",
    "    _LLM_STUB_INSTALLED = False\n",
    "    _LLM_SPY_INSTALLED = False\n",
    "    print(\"Restored.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8b47d",
   "metadata": {},
   "source": [
    "Cell 19 — LLM “호출 여부”를 확실히 증명하는 테스트(스파이/스텁 이용)\n",
    "역할\n",
    "\n",
    "팀원이 제일 많이 묻는 게 이거임:\n",
    "“LLM이 진짜 호출되긴 해?”\n",
    "\n",
    "이 셀은 force_llm=True로 LLM 경로를 강제로 태우고,\n",
    "Cell 20의 spy/stub 카운트로 ‘진짜 호출됐다’를 증명한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ef6128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM stub installed.\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[LLM_STUB] CALLED\n",
      "  - n: 1\n",
      "  - slotName: electricity_usage\n",
      "  - columns: 3\n",
      "[L2] picked\n",
      "  - date_col: A\n",
      "  - flow_col: B\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "used_llm = True\n",
      "date_col = A\n",
      "flow_col = B\n",
      "LLM_CALLS = 1\n",
      "err2 = None\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 19: LLM call proof (NO force_llm param) =====\n",
    "\n",
    "reset_llm_calls()\n",
    "USE_LLM = True\n",
    "\n",
    "# 1) LLM이 항상 date/flow를 이렇게 찍도록 스텁 설치\n",
    "install_llm_stub(mapping={\"A\":\"date\", \"B\":\"flow\", \"C\":\"other\"}, llm_func_name=\"llm_classify_columns_min_tokens\")\n",
    "\n",
    "# 2) 룰/폴백이 못 맞추게: 컬럼명 A,B,C + 데이터도 일부러 애매하게(신호 부족)\n",
    "#    - A: 날짜처럼 보이지만 일부는 깨짐 -> dt_rate 낮게\n",
    "#    - B: 숫자처럼 보이지만 일부는 문자 -> num_rate 낮게\n",
    "ps = \"2026-02-01T00:00:00\"\n",
    "pe = \"2026-02-05T23:45:00\"\n",
    "ts = pd.date_range(pd.to_datetime(ps), pd.to_datetime(pe), freq=\"15min\")\n",
    "\n",
    "A = ts.astype(str).tolist()\n",
    "# 날짜 일부 깨기\n",
    "for i in np.random.choice(len(A), size=40, replace=False):\n",
    "    A[i] = \"날짜아님\"\n",
    "\n",
    "B = np.round(np.random.uniform(10, 60, len(ts)), 3).astype(object)\n",
    "# 숫자 일부 깨기\n",
    "for i in np.random.choice(len(B), size=40, replace=False):\n",
    "    B[i] = \"수치아님\"\n",
    "\n",
    "df = pd.DataFrame({\"A\": A, \"B\": B, \"C\": [\"memo\"]*len(ts)})\n",
    "\n",
    "# 3) L2 호출: 현재 너의 L2는 (rule 부족 && USE_LLM=True)면 LLM 호출함\n",
    "date_col, value_cols, unit_cols, err2, dbg = layer2_find_columns(df, slotName=\"electricity_usage\")\n",
    "\n",
    "print(\"used_llm =\", dbg.get(\"used_llm\"))\n",
    "print(\"date_col =\", date_col)\n",
    "print(\"flow_col =\", value_cols.get(\"flow\"))\n",
    "print(\"LLM_CALLS =\", llm_calls())\n",
    "print(\"err2 =\", err2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b364adec",
   "metadata": {},
   "source": [
    "CELL 21: LLM 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f628bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 [LLM TEST] 시작 시각: 2026-01-21T02:45:04Z\n",
      "📊 테스트 컬럼명: ['X_VAR_999', 'Y_VAL_001', 'Z_REF_ETC']\n",
      "🤖 LLM에게 데이터 샘플을 보내 추론을 요청합니다...\n",
      "[MAIN] start\n",
      "  - slotName: electricity_usage\n",
      "  - file_path: inference_test.xlsx\n",
      "[L0] PASS\n",
      "  - slotName: electricity_usage\n",
      "  - shape: (24, 3)\n",
      "  - period_start: 2025-12-01 00:00:00\n",
      "  - period_end: 2025-12-01 23:00:00\n",
      "[L1] PASS\n",
      "  - columns: ['X_VAR_999', 'Y_VAL_001', 'Z_REF_ETC']\n",
      "[L2] AUTO_LLM_TRIGGERED\n",
      "  - reason: rule_missing\n",
      "  - USE_LLM: True\n",
      "[LLM_STUB] CALLED\n",
      "  - n: 2\n",
      "  - slotName: electricity_usage\n",
      "  - columns: 3\n",
      "[L2] picked\n",
      "  - date_col: X_VAR_999\n",
      "  - flow_col: Y_VAL_001\n",
      "  - cum_col: None\n",
      "  - unit_cols: []\n",
      "[L4] PASS\n",
      "  - rows_in_period: 24\n",
      "{\n",
      "  \"status\": \"PASS\",\n",
      "  \"file_path\": \"inference_test.xlsx\",\n",
      "  \"payload\": {\n",
      "    \"time_granularity\": \"hourly\",\n",
      "    \"unit_schema\": [\n",
      "      \"time\",\n",
      "      \"kWh\",\n",
      "      \"-\"\n",
      "    ],\n",
      "    \"validated_fields\": [\n",
      "      \"timestamp\",\n",
      "      \"flow_kwh\",\n",
      "      \"Z_REF_ETC\"\n",
      "    ]\n",
      "  },\n",
      "  \"processed_at\": \"2026-01-21T02:45:04Z\"\n",
      "}\n",
      "\n",
      "✨ 결과 분석: LLM이 암호화된 컬럼을 성공적으로 매핑했습니다.\n",
      "Restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_145500\\2953140546.py:77: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  [(c, float(pd.to_datetime(df[c], errors=\"coerce\").notna().mean())) for c in cols],\n"
     ]
    }
   ],
   "source": [
    "# ===== Cell 21: LLM Reasoning Test (Inference Check) =====\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def run_llm_inference_test():\n",
    "    # 1. 전역 설정 확인 (Cell 2의 설정이 True여야 함)\n",
    "    if not USE_LLM:\n",
    "        print(\"⚠️ 경고: USE_LLM이 False입니다. 테스트를 위해 True로 변경해주세요.\")\n",
    "        # return\n",
    "\n",
    "    print(f\"🚀 [LLM TEST] 시작 시각: {now_utc_iso()}\")\n",
    "    \n",
    "    # 2. 룰 기반 엔진이 절대 맞출 수 없는 '암호화된' 데이터 생성\n",
    "    # 컬럼명에 'date', 'usage' 같은 힌트가 전혀 없음\n",
    "    data_len = 24  # 테스트용 24시간 데이터\n",
    "    test_df = pd.DataFrame({\n",
    "        \"X_VAR_999\": pd.date_range(\"2025-12-01\", periods=data_len, freq=\"h\"), # 실제: 날짜\n",
    "        \"Y_VAL_001\": np.random.uniform(50, 100, size=data_len),               # 실제: 사용량(flow)\n",
    "        \"Z_REF_ETC\": [\"N/A\"] * data_len                                      # 실제: 잡음 데이터\n",
    "    })\n",
    "\n",
    "    # 3. 검증 객체 구성\n",
    "    obj_test = {\n",
    "        \"slotName\": \"electricity_usage\",\n",
    "        \"kind\": \"EXCEL\",\n",
    "        \"ext\": \"xlsx\",\n",
    "        \"period_start\": \"2025-12-01T00:00:00\",\n",
    "        \"period_end\": \"2025-12-01T23:00:00\",\n",
    "        \"dataframe\": test_df\n",
    "    }\n",
    "\n",
    "    print(f\"📊 테스트 컬럼명: {list(test_df.columns)}\")\n",
    "    print(\"🤖 LLM에게 데이터 샘플을 보내 추론을 요청합니다...\")\n",
    "\n",
    "    # 4. 검증 엔진 실행 (L2에서 LLM이 개입해야 함)\n",
    "    result = validate_structured_upstream(obj_test, file_path=\"inference_test.xlsx\")\n",
    "\n",
    "    # 5. 결과 출력 및 분석\n",
    "    print_full(result)\n",
    "    \n",
    "    if result[\"status\"] == \"PASS\":\n",
    "        print(\"\\n✨ 결과 분석: LLM이 암호화된 컬럼을 성공적으로 매핑했습니다.\")\n",
    "    else:\n",
    "        print(f\"\\n🛑 결과 분석: {result['error']['code']} - {result['error']['message']}\")\n",
    "\n",
    "# 실행\n",
    "run_llm_inference_test()\n",
    "\n",
    "restore_llm()\n",
    "USE_LLM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138336d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
